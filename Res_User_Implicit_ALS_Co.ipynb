{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import os\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "from pandas import DataFrame\n",
    "from scipy.sparse import coo_matrix\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import implicit\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from evaluation import rr, get_user_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/Users/mismael/Documents/projects/ContextualRecsMXNetDev/data/orders-5c-train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bb938286-487e-11e4-9697-9cb654858910</th>\n",
       "      <th>433593</th>\n",
       "      <th>2018-05-10 21:13:08.000</th>\n",
       "      <th>late night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc443afe-487e-11e4-9697-9cb654858910</td>\n",
       "      <td>676517</td>\n",
       "      <td>2018-05-09 17:00:44.000</td>\n",
       "      <td>dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcbee2c2-487e-11e4-9697-9cb654858910</td>\n",
       "      <td>308694</td>\n",
       "      <td>2018-05-29 20:55:09.000</td>\n",
       "      <td>dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bd3c036a-487e-11e4-9697-9cb654858910</td>\n",
       "      <td>303952</td>\n",
       "      <td>2018-05-16 15:05:51.000</td>\n",
       "      <td>mid-day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfabb938-487e-11e4-9697-9cb654858910</td>\n",
       "      <td>383154</td>\n",
       "      <td>2018-05-23 19:23:57.000</td>\n",
       "      <td>dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bfdcb966-487e-11e4-9697-9cb654858910</td>\n",
       "      <td>80559</td>\n",
       "      <td>2018-05-12 16:10:48.000</td>\n",
       "      <td>dinner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bb938286-487e-11e4-9697-9cb654858910  433593  2018-05-10 21:13:08.000  \\\n",
       "0  bc443afe-487e-11e4-9697-9cb654858910  676517  2018-05-09 17:00:44.000   \n",
       "1  bcbee2c2-487e-11e4-9697-9cb654858910  308694  2018-05-29 20:55:09.000   \n",
       "2  bd3c036a-487e-11e4-9697-9cb654858910  303952  2018-05-16 15:05:51.000   \n",
       "3  bfabb938-487e-11e4-9697-9cb654858910  383154  2018-05-23 19:23:57.000   \n",
       "4  bfdcb966-487e-11e4-9697-9cb654858910   80559  2018-05-12 16:10:48.000   \n",
       "\n",
       "  late night  \n",
       "0     dinner  \n",
       "1     dinner  \n",
       "2    mid-day  \n",
       "3     dinner  \n",
       "4     dinner  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path_test=\"/Users/mismael/Documents/projects/ContextualRecsMXNetDev/data/orders-5c-test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train and test\n",
    "\n",
    "def create_user_logs(data_path):\n",
    "    user_item_dict=defaultdict(list)\n",
    "    with open (data_path) as data_file:\n",
    "        for line in data_file:\n",
    "            line_list = line.split(\",\")\n",
    "\n",
    "            user=line_list[0]\n",
    "            #print (user)\n",
    "            rest=line_list[1]\n",
    "            user_item_dict[user].append(rest)\n",
    "    #print (len (user_item_dict))\n",
    "    return user_item_dict\n",
    "\n",
    "\n",
    "\n",
    "def create_user_test_logs(data_path_test):\n",
    "    user_item_dict_test=defaultdict(list)\n",
    "    with open (data_path_test) as data_file:\n",
    "        for line in data_file:\n",
    "            line_list = line.split(\",\")\n",
    "\n",
    "            user=line_list[0]\n",
    "            print (user)\n",
    "            rest=line_list[1]\n",
    "            user_item_dict_test[user].append(rest)\n",
    "    #print (len (user_item_dict_test))\n",
    "    return user_item_dict_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707765\n"
     ]
    }
   ],
   "source": [
    "user_item_dict=create_user_logs(data_path)\n",
    "print (len (user_item_dict))\n",
    "\n",
    "#user_item_dict_test=create_user_test_logs(data_path_test)\n",
    "#print (len (user_item_dict_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find frequency of items per user\n",
    "\n",
    "def find_rest_freq(user_item_dict):\n",
    "    user_list_freq= []\n",
    "    for user in user_item_dict:\n",
    "        #print (user)\n",
    "        list_of_rests = user_item_dict[user]\n",
    "        rest_counter = Counter(list_of_rests)\n",
    "        #print (rest_counter)\n",
    "        for res_id in rest_counter:\n",
    "\n",
    "            freq = rest_counter[res_id]\n",
    "            user_list_freq.append([user, res_id, freq])\n",
    "            #print (user_list_freq)\n",
    "            #print (len (user_list_freq))\n",
    "\n",
    "    headers = ['user', 'restaurant', 'frequency']\n",
    "    datafram = DataFrame(user_list_freq, columns=headers)\n",
    "\n",
    "    #print (user_list_freq)\n",
    "    return datafram\n",
    "\n",
    "\n",
    "#user_item_dict=create_user_logs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafram=find_rest_freq(user_item_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'posixpath' from '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafram['user']=datafram['user'].index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafram.to_csv(\"dinner_item_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Spars matrix or build prefrence item user matrix. \n",
    "\n",
    "def build_ui_matrix(datafram):\n",
    "    datafram['user']=datafram['user'].astype(\"category\")\n",
    "    datafram['restaurant']=datafram['restaurant'].astype(\"category\")\n",
    "    user_order_log_matrix= coo_matrix((datafram['frequency'].astype(numpy.float32),\n",
    "                       (datafram['restaurant'].cat.codes.copy(),\n",
    "                        datafram['user'].cat.codes.copy())))\n",
    "    \n",
    "    return user_order_log_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user_matrix=build_ui_matrix(datafram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5826/5826 [00:00<00:00, 7679.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# make a modeel\n",
    "\n",
    "model = implicit.nearest_neighbours.BM25Recommender()\n",
    "model.fit(item_user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = item_user_matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def reco ( model,userid, user_items, N=10 ):\n",
    "        \"\"\" returns the best N recommendations for a user given its id\"\"\"\n",
    "        # recalculate_user is ignored because this is not a model based algorithm\n",
    "        items = N     \n",
    "        indices, data = model.scorer.recommend(userid, user_items.indptr, user_items.indices,                                              user_items.data, K=items, remove_own_likes=False)\n",
    "        best = sorted(zip(indices, data), key=lambda x: -x[1]) \n",
    "        return list(islice((rec for rec in best ), N))\n",
    "        #return list(itertools.islice((rec for rec in best if rec[0] not in liked), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recomend item to training dataset and create output\n",
    "\n",
    "rests = dict(enumerate(datafram['restaurant'].cat.categories))\n",
    "with open('output_bm25_train', 'w') as out:\n",
    "    for userid, username in enumerate(datafram['user'].cat.categories.tolist()):\n",
    "        for rest_index, score in reco(model,userid, user_items):            \n",
    "            out.write(\"\" + str(username) + \",\"+ str(rests[rest_index])+ \",\" +str (score)+ \"%\\n\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict='/Users/mismael/output_bm25_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make disition for each user in training dateset\n",
    "\n",
    "def create_user_item_predict(train_predict):\n",
    "    user_item_predict=defaultdict(list)\n",
    "    with open (train_predict) as data_file:\n",
    "        for line in data_file:\n",
    "            line_list = line.split(\",\")\n",
    "\n",
    "            user=line_list[0]\n",
    "            rest=line_list[1]\n",
    "            user_item_predict[user].append(rest)\n",
    "    print (len(user_item_predict))\n",
    "    return user_item_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707765\n"
     ]
    }
   ],
   "source": [
    "user_item_precict_result=create_user_item_predict(train_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p:  0.12911487194847984 r:  0.47653163192290043\n"
     ]
    }
   ],
   "source": [
    "# test Bm25 with predicted train with acutal test\n",
    "\n",
    "user_test=0\n",
    "k=4\n",
    "num_past_orders=[]\n",
    "verbose=False\n",
    "precision=[]\n",
    "recall=[]\n",
    "i=0\n",
    "won = 0\n",
    "for key in user_item_dict_test:    \n",
    "\n",
    "    if key in user_item_precict_result:\n",
    "\n",
    "        predictions=user_item_precict_result[key]\n",
    "        \n",
    "        targets=user_item_dict_test[key]\n",
    "        #hithit = len(set(predictions).intersection(set(actual_lastweek)))\n",
    "    \n",
    "        #print ('target',type(targets[0]))\n",
    "                               \n",
    "        predictions = predictions[:k] # get top k goto restaurants\n",
    "        #print (\"p\", type(predictions[0]))\n",
    "        #print (len (predictions))\n",
    "        num_hit = len(set(predictions).intersection(set(targets))) #get true positives\n",
    "\n",
    "        user_precision = float(num_hit) / len(predictions) #divide by k\n",
    "        #print (user_precision)\n",
    "        user_recall = float(num_hit) / len(targets) \n",
    "        #print (user_recall)\n",
    "        precision.append(user_precision)\n",
    "        recall.append(user_recall)\n",
    "        \n",
    "\n",
    "print(i, \"p: \", np.mean(np.array(precision)), \"r: \", np.mean(np.array(recall)) )\n",
    "        \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p:  0.5830443720726515 r:  0.32940496344098\n"
     ]
    }
   ],
   "source": [
    "# test Bm25 with predicted train with acutal train\n",
    "\n",
    "\n",
    "user_test=0\n",
    "k=15\n",
    "num_past_orders=[]\n",
    "verbose=False\n",
    "precision=[]\n",
    "recall=[]\n",
    "i=0\n",
    "won = 0\n",
    "for key in user_item_dict:    \n",
    "\n",
    "    if key in user_item_precict_result:\n",
    "\n",
    "        predictions=user_item_precict_result[key]\n",
    "        \n",
    "        targets=user_item_dict[key]\n",
    "        #hithit = len(set(predictions).intersection(set(actual_lastweek)))\n",
    "    \n",
    "        #print ('target',type(targets[0]))\n",
    "                               \n",
    "        predictions = predictions[:k] # get top k goto restaurants\n",
    "        #print (\"p\", type(predictions[0]))\n",
    "        #print (len (predictions))\n",
    "        num_hit = len(set(predictions).intersection(set(targets))) #get true positives\n",
    "\n",
    "        user_precision = float(num_hit) / len(predictions) #divide by k\n",
    "        #print (user_precision)\n",
    "        user_recall = float(num_hit) / len(targets) \n",
    "        #print (user_recall)\n",
    "        precision.append(user_precision)\n",
    "        recall.append(user_recall)\n",
    "        \n",
    "\n",
    "print(i, \"p: \", np.mean(np.array(precision)), \"r: \", np.mean(np.array(recall)) )\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p:  0.06477609704957316 r:  0.5936376246687763\n"
     ]
    }
   ],
   "source": [
    "user_test=0\n",
    "k=15\n",
    "num_past_orders=[]\n",
    "verbose=False\n",
    "precision=[]\n",
    "recall=[]\n",
    "i=0\n",
    "for key in user_item_dict_test.keys():    \n",
    "    #print (key)\n",
    "    if key in user_item_precict_result.keys():\n",
    "        #print (key )\n",
    "        predictions=user_item_precict_result[key]\n",
    "        \n",
    "        targets=user_item_dict_test[key]\n",
    "        #print (len (targets))\n",
    "                               \n",
    "        predictions = predictions[:k] # get top k goto restaurants\n",
    "        #print (predictions)\n",
    "        num_hit = len(set(predictions).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(predictions) #divide by k\n",
    "        #print (user_precision)\n",
    "        user_recall = float(num_hit) / len(targets) \n",
    "        #print (user_recall)\n",
    "        precision.append(user_precision)\n",
    "        recall.append(user_recall)\n",
    "print(i, \"p: \", np.array(precision).squeeze().mean(), \"r: \", np.array(recall).squeeze().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_item_dict_test_goto=create_user_test_logs_goto(data_path_test_goto)\n",
    "#print (len (user_item_dict_test_goto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:32<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "model1.fit(item_user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_items = item_user_matrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, (5826, 50))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model1.user_factors.shape), model1.item_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model1.recommend(userid, user_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "related = model.similar_items(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index_id={}\n",
    "for userid, username in enumerate(datafram['user'].cat.categories.tolist()):   \n",
    "    user_index_id[userid]=(username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_latent=defaultdict(list)\n",
    "for item_inex, headen_item in enumerate (model1.item_factors):   \n",
    "    item_latent[item_inex].append(headen_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5826"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recol ( model,userid, user_items, N=10 ):\n",
    "        \"\"\" returns the best N recommendations for a user given its id\"\"\"\n",
    "        # recalculate_user is ignored because this is not a model based algorithm\n",
    "        items = N     \n",
    "        indices, data = model1.recommend(userid, user_items.indptr, user_items.indices,                                              user_items.data, K=items, remove_own_likes=False)\n",
    "        best = sorted(zip(indices, data), key=lambda x: -x[1]) \n",
    "        return list(islice((rec for rec in best ), N))\n",
    "rests = dict(enumerate(datafram['restaurant'].cat.categories))\n",
    "with open('output_ALS', 'w') as out:\n",
    "    for userid, username in enumerate(datafram['user'].cat.categories.tolist()):\n",
    "        for rest_index, score in model1.recommend(userid, user_items):        \n",
    "            out.write(\"\" + str(username) + \",\"+ str(rests[rest_index])+ \",\" +str (score)+ \"%\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_ALS='output_ALS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707765\n",
      "707765\n"
     ]
    }
   ],
   "source": [
    "def create_user_item_predict_ALS(train_predict_ALS):\n",
    "    user_item_predict_ALS=defaultdict(list)\n",
    "    with open (train_predict_ALS) as data_file:\n",
    "        for line in data_file:\n",
    "            line_list = line.split(\",\")\n",
    "\n",
    "            user=line_list[0]\n",
    "            rest=line_list[1]\n",
    "            user_item_predict_ALS[user].append(rest)\n",
    "    print (len (user_item_predict_ALS))\n",
    "    return user_item_predict_ALS\n",
    "\n",
    "user_item_precict_result_ALS=create_user_item_predict_ALS(train_predict_ALS)\n",
    "print (len (user_item_precict_result_ALS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p : ALS 0.00296914782087764 r:  0.010946782487144925\n"
     ]
    }
   ],
   "source": [
    "user_test=0\n",
    "k=4\n",
    "num_past_orders=[]\n",
    "verbose=False\n",
    "precision_ALS=[]\n",
    "recall_ALS=[]\n",
    "i=0\n",
    "for key in user_item_dict_test.keys():    \n",
    "    #print (key)\n",
    "    if key in user_item_precict_result_ALS.keys():\n",
    "        #print (key )\n",
    "        predictions=user_item_precict_result_ALS[key]\n",
    "        \n",
    "        targets=user_item_dict_test[key]\n",
    "        #print (len (targets))\n",
    "                               \n",
    "        predictions = predictions[:k] # get top k goto restaurants\n",
    "        #print (len (predictions))\n",
    "        num_hit = len(set(predictions).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(predictions) #divide by k\n",
    "        #print (user_precision)\n",
    "        user_recall = float(num_hit) / len(targets) \n",
    "        #print (user_recall)\n",
    "        precision_ALS.append(user_precision)\n",
    "        recall_ALS.append(user_recall)\n",
    "print(i, \"p : ALS\", np.array(precision_ALS).mean(), \"r: \", np.array(recall_ALS).mean())\n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot product between useritem.itemuser=u.u\n",
    "        \n",
    "def get_related( user_factors, item_factors, N=50):\n",
    "        # scores = self.factors.dot(self.factors[artistid])\n",
    "        scores = item_factors.dot(user_factors)\n",
    "        best = numpy.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index_id={}\n",
    "for userid, username in enumerate(datafram['user'].cat.categories.tolist()):       \n",
    "    user_index_id[userid]=(username)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index_id={}\n",
    "for userid, username in enumerate(datafram['user'].cat.categories.tolist()):   \n",
    "    user_index_id[userid]=(username)\n",
    "\n",
    "\n",
    "user_latent_index=defaultdict(list)\n",
    "for user_inex, headen_item in enumerate (model1.user_factors): \n",
    "    #print (user_inex)\n",
    "    real_user=user_index_id[user_inex]\n",
    "    #print (real_user)\n",
    "    user_latent_index[real_user].append(headen_item)\n",
    "    \n",
    "    \n",
    "with open('user_latent_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(user_latent_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('user_latent_index.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_index_id={}\n",
    "for userid, username in enumerate(datafram['restaurant'].cat.categories.tolist()):   \n",
    "    item_index_id[userid]=(username)\n",
    "    \n",
    "item_latent_index=defaultdict(list)\n",
    "for user_inex, headen_item in enumerate (model1.item_factors): \n",
    "    real_item=item_index_id[user_inex]\n",
    "    #print (real_user)\n",
    "    item_latent_index[real_item].append(headen_item)    \n",
    "    \n",
    "\n",
    "with open('item_latent_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(item_latent_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_latent_index.pickle', 'rb') as handle:\n",
    "    h = pickle.load(handle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = model1.item_factors\n",
    "\n",
    "recommended = defaultdict(list)\n",
    "for index, user_factor in enumerate(model1.user_factors):\n",
    "\n",
    "    for item_index, score in get_related(user_factor,item_factors, N=10):\n",
    "        #print(item_index)\n",
    "        item_value=item_index_id[item_index]\n",
    "        \n",
    "        recommended[index].append((item_value,score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preaper data to evaluate\n",
    "user_item_latent = defaultdict(list)\n",
    "for user_index  in recommended:\n",
    "    real_user=user_index_id[user_index]\n",
    "    score=recommended[user_index]\n",
    "    item_=([i[0] for i in score])\n",
    "    user_item_latent[real_user].append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p : ALS 0.05755578852778194 r:  0.21349183765163998\n"
     ]
    }
   ],
   "source": [
    "#Evaluate ALS (latent features ) predicted training data set with test\n",
    "\n",
    "user_test=0\n",
    "k=4\n",
    "num_past_orders=[]\n",
    "precision_ALS_latent=[]\n",
    "recall_ALS_latent=[]\n",
    "i=0\n",
    "for key in user_item_dict_test.keys():    \n",
    "    #print (key)\n",
    "    if key in user_item_latent.keys():\n",
    "\n",
    "        predictions=user_item_latent[key]\n",
    "        prediction=list(chain.from_iterable(predictions))\n",
    "        targets=user_item_dict_test[key]        \n",
    "        #print (targets)                               \n",
    "        prediction = prediction[:k] # get top k goto restaurants\n",
    "        #print (prediction)\n",
    "        #print (prediction)\n",
    "        #print (targets)\n",
    "        #print (len (predictions))\n",
    "        num_hit = len(set(prediction).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(prediction) #divide by k\n",
    "        #print (user_precision)\n",
    "        if len (targets)>0:\n",
    "            user_recall = float(num_hit) / len(targets) \n",
    "            #print (user_recall)\n",
    "        precision_ALS_latent.append(user_precision)\n",
    "        recall_ALS_latent.append(user_recall)\n",
    "print(i, \"p : ALS\", np.array(precision_ALS_latent).mean(), \"r: \", np.array(recall_ALS_latent).mean())\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 p : ALS 0.39454727204651263 r:  0.08598053370833918\n"
     ]
    }
   ],
   "source": [
    "#Evaluate ALs (latent features )with predicted traininga data set with actual dataset\n",
    "\n",
    "user_test=0\n",
    "k=4\n",
    "num_past_orders=[]\n",
    "\n",
    "precision_ALS_latent=[]\n",
    "recall_ALS_latent=[]\n",
    "i=0\n",
    "for key in user_item_dict:    \n",
    "    #print (key)\n",
    "    if key in user_item_latent:\n",
    "\n",
    "        predictions=user_item_latent[key]\n",
    "        prediction=list(chain.from_iterable(predictions))\n",
    "        #print(prediction)\n",
    "        \n",
    "        targets=user_item_dict[key]        \n",
    "        #print (targets)\n",
    "                               \n",
    "        prediction = prediction[:k] # get top k goto restaurants\n",
    "        #print (prediction)\n",
    "        #print (prediction)\n",
    "        #print (targets)\n",
    "        #print (len (predictions))\n",
    "        num_hit = len(set(prediction).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(prediction) #divide by k\n",
    "        #print (user_precision)\n",
    "        if len (targets)>0:\n",
    "            user_recall = float(num_hit) / len(targets) \n",
    "            #print (user_recall)\n",
    "        precision_ALS_latent.append(user_precision)\n",
    "        recall_ALS_latent.append(user_recall)\n",
    "print(i, \"p : ALS\", np.array(precision_ALS_latent).squeeze().mean(), \"r: \", np.array(recall_ALS_latent).squeeze().mean())\n",
    "                  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normilize by Bm25 and ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:43<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "logging.debug(\"weighting matrix by bm25_weight\")\n",
    "normal_user_item_matrix = bm25_weight(item_user_matrix)\n",
    "als_normal_bm= implicit.als.AlternatingLeastSquares()\n",
    "als_normal_bm.fit(normal_user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((707765, 100), (5826, 100))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_normal_bm.user_factors.shape, als_normal_bm.item_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h=normal_user_item_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_latent_bm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2f1253e99adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mitem_latent_bm25\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem_inex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaden_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mals_normal_bm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mitem_latent_bm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_inex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaden_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'item_latent_bm' is not defined"
     ]
    }
   ],
   "source": [
    "item_latent_bm25=defaultdict(list)\n",
    "for item_inex, headen_item in enumerate (als_normal_bm.item_factors):   \n",
    "    item_latent_bm[item_inex].append(headen_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_als_normlize( item_factors_als_normal,user_factor,  N=50):\n",
    "        # scores = self.factors.dot(self.factors[artistid])\n",
    "    \n",
    "        scores = item_factors_als_normal.dot(user_factor)\n",
    "        best = numpy.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "    \n",
    "      \n",
    "item_factors_als_normal = als_normal_bm.item_factors\n",
    "recommended_als = defaultdict(list)\n",
    "for index, user_factor in enumerate(als_normal_bm.user_factors):\n",
    "\n",
    "\n",
    "    for item_index, score in get_related_als_normlize(item_factors_als_normal,user_factor, N=10):\n",
    "        item_value=item_index_id[item_index]\n",
    "        recommended_als[index].append((item_value,score))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_latent_norm = defaultdict(list)\n",
    "for user_index  in recommended_als:\n",
    "    #print (user_index)\n",
    "    real_user=user_index_id[user_index]\n",
    "    score=recommended_als[user_index]\n",
    "    item_=([i[0] for i in score])\n",
    "    user_item_latent_norm[real_user].append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mean.precision: ALS 0.04277519844241426 mean.recall:  0.39657822690846506\n"
     ]
    }
   ],
   "source": [
    "user_test=0\n",
    "k=10\n",
    "num_past_orders=[]\n",
    "\n",
    "precision_ALS_latent_norm=[]\n",
    "recall_ALS_latent_norm=[]\n",
    "i=0\n",
    "for key in user_item_dict_test.keys():    \n",
    "    #print (key)\n",
    "    if key in user_item_latent_norm.keys():\n",
    "\n",
    "        predictions=user_item_latent_norm[key]\n",
    "        prediction=list(chain.from_iterable(predictions))   \n",
    "        targets=user_item_dict_test[key]        \n",
    "                               \n",
    "        prediction = prediction[:k] # get top k goto restaurants\n",
    "\n",
    "        num_hit = len(set(prediction).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(prediction) #divide by k\n",
    "        #print (user_precision)\n",
    "        if len (targets)>0:\n",
    "            user_recall = float(num_hit) / len(targets) \n",
    "            #print (user_recall)\n",
    "        precision_ALS_latent_norm.append(user_precision)\n",
    "        recall_ALS_latent_norm.append(user_recall)\n",
    "print(i, \"mean.precision: ALS\", np.array(precision_ALS_latent_norm).mean(), \"mean.recall: \", np.array(recall_ALS_latent_norm).mean())\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS normolize BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:30<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "logging.debug(\"weighting matrix by bm25_weight\")\n",
    "normal_user_item_matrixT = bm25_weight(item_user_matrix.T)\n",
    "als_normal_bmT= implicit.als.AlternatingLeastSquares(factors=50)\n",
    "als_normal_bmT.fit(normal_user_item_matrixT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5826\n",
      "707765\n"
     ]
    }
   ],
   "source": [
    "print (len(als_normal_bmT.user_factors))\n",
    "print (len (als_normal_bmT.item_factors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_als_normlizeT( user_factors_als_normalT,item_factor,  N=50):\n",
    "        # scores = self.factors.dot(self.factors[artistid])\n",
    "        scores = user_factors_als_normalT.dot(item_factor)\n",
    "        best = numpy.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "    \n",
    "      \n",
    "item_factors_als_normalT = als_normal_bmT.item_factors\n",
    "user_factors_als_normalT = als_normal_bmT.user_factors\n",
    "recommended_alsT = defaultdict(list)\n",
    "for index, item_factor in enumerate(item_factors_als_normalT):\n",
    "\n",
    "\n",
    "    for item_index, score in get_related_als_normlizeT(user_factors_als_normalT,item_factor, N=10):\n",
    "        item_value=item_index_id[item_index]\n",
    "        recommended_alsT[index].append((item_value,score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_latent_norm_T = defaultdict(list)\n",
    "for user_index  in recommended_alsT:\n",
    "    #print (user_index)\n",
    "    real_user=user_index_id[user_index]\n",
    "    score=recommended_alsT[user_index]\n",
    "    item_=([i[0] for i in score])\n",
    "    user_item_latent_norm_T[real_user].append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mean.precision: ALS 0.03862812640407368 mean.recall:  0.3563834330597099\n"
     ]
    }
   ],
   "source": [
    "user_test=0\n",
    "k=10\n",
    "num_past_orders=[]\n",
    "\n",
    "precision_ALS_latent_normT=[]\n",
    "recall_ALS_latent_normT=[]\n",
    "i=0\n",
    "for key in user_item_dict_test.keys():    \n",
    "    #print (key)\n",
    "    if key in user_item_latent_norm_T.keys():\n",
    "\n",
    "        predictions=user_item_latent_norm_T[key]\n",
    "        prediction=list(chain.from_iterable(predictions))   \n",
    "        targets=user_item_dict_test[key]        \n",
    "                               \n",
    "        prediction = prediction[:k] # get top k goto restaurants\n",
    "\n",
    "        num_hit = len(set(prediction).intersection(set(targets))) #get true positives\n",
    "        #print (num_hit)\n",
    "        user_precision = float(num_hit) / len(prediction) #divide by k\n",
    "        #print (user_precision)\n",
    "        if len (targets)>0:\n",
    "            user_recall = float(num_hit) / len(targets) \n",
    "            #print (user_recall)\n",
    "        precision_ALS_latent_normT.append(user_precision)\n",
    "        recall_ALS_latent_normT.append(user_recall)\n",
    "print(i, \"mean.precision: ALS\", np.array(precision_ALS_latent_normT).mean(), \"mean.recall: \", np.array(recall_ALS_latent_normT).mean())\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
